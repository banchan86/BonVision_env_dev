<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Display Environments | Bonvision </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Display Environments | Bonvision ">
      
      
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/bonvision/BonVision/blob/main/docs/articles/display-environment-basics.md/#L1">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="&#160; Bonvision">
            &#160; Bonvision
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled="" placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="">
<h1 id="display-environments">Display Environments</h1>

<p>Visual neuroscience is almost always carried out in eye-centric coordinates, which defines stimuli in terms of <em>visual angle</em> subtended at the eye. This helps keep the definition of the image that reaches the retina consistent. However, visual displays work in pixel coordinates (with specific physical characteristics) and to draw accurate stimuli one has to calculate the conversion between the two coordinate frames. This requires a new transform function to be calculated for any display, and few programs are available to help with this.</p>
<p>In the following sections we describe the main assumptions and design decisions in BonVision for dealing with a broad family of visual stimuli, both 2D and 3D.</p>
<h2 id="environmental-mapping">Environmental mapping</h2>
<p>One of the major goals for BonVision was to unify the specification of both 2D and 3D visual environments into a common representation that would allow sharing experiments across multiple display configurations, including domes, toruses, display grids and other geometrical arrangements.</p>
<p>To achieve this, the main design decision was to decouple the Display environment from the Stimulus Generation logic. This allows users of BonVision to write tasks in standard units (either degrees of visual field for 2D or metric units for 3D), and then run them unmodified on any correctly calibrated rig.</p>
<p>We use <a href="https://en.wikipedia.org/wiki/Cube_mapping">cube mapping</a> as a way to efficiently specify the entire surrounding environment of an experimental subject, both for 2D and 3D environments. In this technique, 6 different faces of a cube, each covering exactly a 90º field of view volume, are combined to describe the entire 360º environment (a.k.a. a skybox):</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/b/b4/Skybox_example.png" width="500" alt="Skybox Example"></p>
<p>At runtime, each screen becomes a window that looks out into that surrounding environment, with each pixel uniquely specifying a direction vector out into the world. In a cubemap, this direction vector is used to sample the correct pixels from the cubemap textures, therefore projecting onto the screen the corresponding portion of the visual field.</p>
<p><img src="../images/DisplayLogic/CubeMapping.svg" width="500" alt="CubeMapping"></p>
<p>Once the cube mapping rendering pipeline is in place, we can very efficiently generate an arbitrary number of projections into the visual space for each display in the experiment. The remaining challenge is then how to generate the 6 faces of the cubemap in a way that accurately represents the visual field surrounding the subject.</p>
<h3 id="3d-stimuli">3D Stimuli</h3>
<p>For 3D scenes, there is a straightforward solution: render the visual scene once for each face of the cube, with a perspective 90º field of view, as seen from the observer. Each rendered perspective will fill exactly one face of the cube. For example:</p>
<p><img src="../images/DisplayLogic/CubeMapSkybox.png" width="500" alt="CubeMapSkybox"></p>
<p>Using the cube mapping pipeline, one can then point a viewing window at any direction and get a correct rendition of the surrounding environment at those pixels:</p>
<p><img src="../images/DisplayLogic/CubemapEnvironment.webp" width="500" alt="CubemapEnvironment"></p>
<h3 id="2d-stimuli">2D Stimuli</h3>
<p>For 2D scenes, such as those containing gabor patches, checkerboards, gratings, random dots and so on, we would like to specify our environments in an orthonormal space, where X and Y represent longitude and latitude, respectively, in degrees of visual field. For example, below is a checkerboard stimulus covering 100 degrees of visual field horizontally and vertically, where each square subtends 10 degrees:</p>
<p><img src="../images/DisplayLogic/CheckerBoard.jpg" width="500" alt="Checkerboard"></p>
<p>To correctly display this environment using the cubemap rendering approach, we need to map this 2D orthonormal space into a 3D spherical environment, which we can then cubemap the same way as for 3D environments. This is essentially the reverse cartographer's problem of specifying a <a href="https://en.wikipedia.org/wiki/Map_projection">map projection</a> of the sphere onto a planar surface.</p>
<p>Unfortunately, there is no perfect way of mapping a sphere onto a plane. Different transformations will preserve different features, e.g. area-preserving, distance-preserving, shape-preserving, etc, and in general we will always need to tradeoff one against the other. For example, a popular mapping is the equirectangular, or cylindrical mapping:</p>
<p><img src="../images/DisplayLogic/CylindricalMapping.png" width="500" alt="CylindricalMapping"></p>
<p>This projection features asymmetrical distortion in both axes, which preserves the meridian lines as vertical lines in the mapping, and introduces distortion around the poles:</p>
<p><img src="../images/DisplayLogic/CheckerBoardMapped.jpg" width="500" alt="CheckerboardMapped"></p>
<p>Other projections remove the distortion at the poles by distributing it across different portions of the image. For example, the icosphere tiles the surface using multiple triangle subdivisions:</p>
<p><img src="../images/DisplayLogic/IcosphereMapping.png" width="500" alt="IcosphereMapping"></p>
<p>The disadvantage is that the arrangement of the planar mapping is not orthonormal anymore, especially at the poles. At the moment BonVision makes use of a cylindrical projection, but improvements are being discussed at the moment to support different kinds of spherical mapping strategies to cover a larger number of cases.</p>
<p><a href="https://en.wikibooks.org/wiki/Blender_3D:_Noob_to_Pro/UV_Map_Basics">More details on spherical mapping from the point of view of modelling software</a></p>
<h2 id="virtual-reality-vs-augmented-reality">Virtual Reality vs Augmented Reality</h2>
<ul>
<li>Shawn's note - This needs more clarity as they both seem to be the same (fixed window/eye, objects/environment move around).</li>
</ul>
<h3 id="virtual-reality-vr">Virtual Reality (VR)</h3>
<p>VR can be easily defined as a situation where the eye, and the screens (windows) are fixed positions, while all the objects (or VR environment) moves across the eye.</p>
<p><img src="../images/DisplayLogic/VRcartoon.png" width="500" alt="VR"></p>
<p>Example rendering to be added here</p>
<h3 id="for-augmented-reality-ar">For Augmented Reality (AR)</h3>
<p>This is a scenario where, generally, the screens remain in a fixed position and the animal can move around. Since we have an eye-centric coordinate frame, the objects and the screen move around to generate an AR.</p>
<p><img src="../images/DisplayLogic/ARcartoon.jpg" width="500" alt="AR"></p>
<p>Example rendering to be added here</p>

</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/bonvision/BonVision/blob/main/docs/articles/display-environment-basics.md/#L1" class="edit-link">Edit this page</a>
        </div>

        <div class="next-article d-print-none border-top" id="nextArticle"></div>

      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          &copy; 2024 Aman Saleem. Made with <a href="https://dotnet.github.io/docfx">docfx</a>
        </div>
      </div>
    </footer>
  </body>
</html>
