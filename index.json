{
  "api/BonVision.AngleProperty.html": {
    "href": "api/BonVision.AngleProperty.html",
    "title": "Class AngleProperty | Bonvision",
    "keywords": "AngleProperty source Operator Inputs & Outputs /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } float /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } Observable float Properties Property Type Description Value float ValueXml float Relationships Namespace - BonVision Assembly - BonVision.dll Inheritance object AngleProperty"
  },
  "api/BonVision.Collections.CreateGratingTrial.html": {
    "href": "api/BonVision.Collections.CreateGratingTrial.html",
    "title": "Class CreateGratingTrial | Bonvision",
    "keywords": "CreateGratingTrial transform Operator Inputs & Outputs /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } Processes an observable sequence into a new sequence of the specified element type. GratingParameters The source sequence to process. GratingTrial An observable sequence with elements of type GratingTrial. /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } Observable GratingTrial Properties Property Type Description Contrast float Delay float Diameter float Duration float Orientation float OrientationXml float SpatialFrequency float TemporalFrequency float X float Y float Relationships Namespace - BonVision.Collections Assembly - BonVision.dll Inheritance object Combinator<GratingParameters, GratingTrial> Transform<GratingParameters, GratingTrial> CreateGratingTrial"
  },
  "api/BonVision.Collections.GratingParameters.html": {
    "href": "api/BonVision.Collections.GratingParameters.html",
    "title": "Class GratingParameters | Bonvision",
    "keywords": "GratingParameters Properties Property Type Description Contrast float? ContrastSpecified bool Delay float? DelaySpecified bool Diameter float? DiameterSpecified bool Duration float? DurationSpecified bool Orientation float? OrientationSpecified bool OrientationXml float? SpatialFrequency float? SpatialFrequencySpecified bool TemporalFrequency float? TemporalFrequencySpecified bool X float? XSpecified bool Y float? YSpecified bool Relationships Namespace - BonVision.Collections Assembly - BonVision.dll Inheritance object GratingParameters"
  },
  "api/BonVision.Collections.GratingSequence.html": {
    "href": "api/BonVision.Collections.GratingSequence.html",
    "title": "Class GratingSequence | Bonvision",
    "keywords": "GratingSequence workflow Operator Presents a sequence of predefined grating stimuli. Inputs & Outputs Properties Property Type Description Phase Placeholder The optional phase offset of the grating stimulus, in degrees. SquareWave Placeholder A value specifying whether to use a sine or square wave function as a basis for the stimulus. Radius Placeholder The normalized radius of the clipping mask applied to the stimulus. Aperture Placeholder The optional variance of the gaussian mask applied to the stimulus. A value of zero specifies that no mask should be applied. Opacity Placeholder The normalized opacity of the stimulus. Zero is fully transparent, and one is fully opaque. Relationships Namespace - BonVision.Collections Assembly - GratingSequence.dll GratingSequence"
  },
  "api/BonVision.Collections.GratingTrial.html": {
    "href": "api/BonVision.Collections.GratingTrial.html",
    "title": "Class GratingTrial | Bonvision",
    "keywords": "GratingTrial Properties Property Type Description Contrast float Delay float Diameter float Duration float Id float Orientation float SpatialFrequency float TemporalFrequency float X float Y float Relationships Namespace - BonVision.Collections Assembly - BonVision.dll Inheritance object GratingTrial"
  },
  "api/BonVision.Collections.GratingsSpecification.html": {
    "href": "api/BonVision.Collections.GratingsSpecification.html",
    "title": "Class GratingsSpecification | Bonvision",
    "keywords": "GratingsSpecification source Operator Inputs & Outputs /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } GratingParameters /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } Observable GratingParameters Properties Property Type Description Trials List<GratingParameters> Relationships Namespace - BonVision.Collections Assembly - BonVision.dll Inheritance object GratingsSpecification"
  },
  "api/BonVision.Collections.SparseNoise.html": {
    "href": "api/BonVision.Collections.SparseNoise.html",
    "title": "Class SparseNoise | Bonvision",
    "keywords": "SparseNoise workflow Operator Generates and draws a non-overlapping discrete sparse grid of randomly activated quads. Inputs & Outputs Properties Property Type Description Duration Placeholder Gets or sets the period to produce subsequent values. If this value is undefined or equal to zero the timer will only fire once. ActiveQuads Placeholder The number of active quads in the generated grid. GridSize Placeholder The size of the sparse noise grid. Relationships Namespace - BonVision.Collections Assembly - SparseNoise.dll SparseNoise"
  },
  "api/BonVision.Collections.html": {
    "href": "api/BonVision.Collections.html",
    "title": "Namespace BonVision.Collections | Bonvision",
    "keywords": ""
  },
  "api/BonVision.CreateSparseNoiseGrid.html": {
    "href": "api/BonVision.CreateSparseNoiseGrid.html",
    "title": "Class CreateSparseNoiseGrid | Bonvision",
    "keywords": "CreateSparseNoiseGrid transform Operator Inputs & Outputs /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } Observable byte[] /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } Observable byte[] Properties Property Type Description ActiveQuads int Columns int Rows int Relationships Namespace - BonVision Assembly - BonVision.dll Inheritance object CreateSparseNoiseGrid"
  },
  "api/BonVision.CreateSphereGrid.html": {
    "href": "api/BonVision.CreateSphereGrid.html",
    "title": "Class CreateSphereGrid | Bonvision",
    "keywords": "CreateSphereGrid source Operator Inputs & Outputs /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } Matrix2x3[], int[]> /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } Observable Matrix2x3[], int[]> Properties Property Type Description Bottom float Left float Right float Top float Relationships Namespace - BonVision Assembly - BonVision.dll Inheritance object CreateSphereGrid"
  },
  "api/BonVision.CreateTextureScale.html": {
    "href": "api/BonVision.CreateTextureScale.html",
    "title": "Class CreateTextureScale | Bonvision",
    "keywords": "CreateTextureScale source Operator Inputs & Outputs /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } Generates an observable sequence of data elements. Vector2 An observable sequence of data elements of type OpenTK.Vector2. /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } Observable Vector2 Properties Property Type Description X float Y float Relationships Namespace - BonVision Assembly - BonVision.dll Inheritance object Source<Vector2> CreateTextureScale"
  },
  "api/BonVision.CreateTextureShift.html": {
    "href": "api/BonVision.CreateTextureShift.html",
    "title": "Class CreateTextureShift | Bonvision",
    "keywords": "CreateTextureShift source Operator Inputs & Outputs /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } Generates an observable sequence of data elements. Vector2 An observable sequence of data elements of type OpenTK.Vector2. /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } Observable Vector2 Properties Property Type Description X float Y float Relationships Namespace - BonVision Assembly - BonVision.dll Inheritance object Source<Vector2> CreateTextureShift"
  },
  "api/BonVision.CreateVertexGrid.html": {
    "href": "api/BonVision.CreateVertexGrid.html",
    "title": "Class CreateVertexGrid | Bonvision",
    "keywords": "CreateVertexGrid transform Operator Inputs & Outputs /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } float[] Matrix2x3[] Relationships Namespace - BonVision Assembly - BonVision.dll Inheritance object CreateVertexGrid"
  },
  "api/BonVision.Environment.CubemapView.html": {
    "href": "api/BonVision.Environment.CubemapView.html",
    "title": "Class CubemapView | Bonvision",
    "keywords": "CubemapView workflow Operator Specifies multiple views used to render the six different faces of a cubemap texture. Inputs & Outputs Properties Property Type Description Eye Placeholder Gets or sets the eye, or camera position, in the world coordinate frame. NearClip Placeholder Gets or sets the distance to the near clip plane. FarClip Placeholder Gets or sets the distance to the far clip plane. Light Placeholder The position of the main point light. Relationships Namespace - BonVision.Environment Assembly - CubemapView.dll CubemapView"
  },
  "api/BonVision.Environment.DrawViewport.html": {
    "href": "api/BonVision.Environment.DrawViewport.html",
    "title": "Class DrawViewport | Bonvision",
    "keywords": "DrawViewport workflow Operator Renders all currently stored draw commands to the specified viewport. Inputs & Outputs Properties Property Type Description X Placeholder The x-coordinate of the lower-left corner of the viewport rectangle, as a fraction of total number of pixels in the window width. Y Placeholder The y-coordinate of the lower-left corner of the viewport rectangle, as a fraction of total number of pixels in the window height. Width Placeholder The width of the viewport rectangle as a fraction of total number of pixels in the window width. Height Placeholder The height of the viewport rectangle as a fraction of total number of pixels in the window height. Relationships Namespace - BonVision.Environment Assembly - DrawViewport.dll DrawViewport"
  },
  "api/BonVision.Environment.GammaCorrection.html": {
    "href": "api/BonVision.Environment.GammaCorrection.html",
    "title": "Class GammaCorrection | Bonvision",
    "keywords": "GammaCorrection workflow Operator Renders the current scene to a texture and applies gamma correction as a post-processing effect. Inputs & Outputs Properties Property Type Description ClearColor Placeholder Gets or sets the color used to clear the framebuffer before rendering. GammaLut Placeholder Gets or sets the name of the image file. Relationships Namespace - BonVision.Environment Assembly - GammaCorrection.dll GammaCorrection"
  },
  "api/BonVision.Environment.HmdView.html": {
    "href": "api/BonVision.Environment.HmdView.html",
    "title": "Class HmdView | Bonvision",
    "keywords": "HmdView workflow Operator Specifies stereo views used to render head-mounted display environments. Inputs & Outputs Properties Property Type Description Light Placeholder The position of the main point light. Relationships Namespace - BonVision.Environment Assembly - HmdView.dll HmdView"
  },
  "api/BonVision.Environment.MeshMapping.html": {
    "href": "api/BonVision.Environment.MeshMapping.html",
    "title": "Class MeshMapping | Bonvision",
    "keywords": "MeshMapping workflow Operator Renders the current scene to a texture and applies mesh mapping and brightness correction as a post-processing effect. Inputs & Outputs Properties Property Type Description ClearColor Placeholder Gets or sets the color used to clear the framebuffer before rendering. FileName Placeholder Gets or sets the name of the CSV file. Relationships Namespace - BonVision.Environment Assembly - MeshMapping.dll MeshMapping"
  },
  "api/BonVision.Environment.NormalizedView.html": {
    "href": "api/BonVision.Environment.NormalizedView.html",
    "title": "Class NormalizedView | Bonvision",
    "keywords": "NormalizedView workflow Operator Specifies an orthographic view with normalized screen coordinates for rapid prototyping of 2D environments. Inputs & Outputs Relationships Namespace - BonVision.Environment Assembly - NormalizedView.dll NormalizedView"
  },
  "api/BonVision.Environment.OrthographicView.html": {
    "href": "api/BonVision.Environment.OrthographicView.html",
    "title": "Class OrthographicView | Bonvision",
    "keywords": "OrthographicView workflow Operator Specifies an orthographic view, commonly used for 2D stimulus environments. Inputs & Outputs Properties Property Type Description Left Placeholder The left boundary of the orthographic environment. Right Placeholder The right boundary of the orthographic environment. Bottom Placeholder The bottom boundary of the orthographic environment. Top Placeholder The top boundary of the orthographic environment. Relationships Namespace - BonVision.Environment Assembly - OrthographicView.dll OrthographicView"
  },
  "api/BonVision.Environment.PerspectiveMapping.html": {
    "href": "api/BonVision.Environment.PerspectiveMapping.html",
    "title": "Class PerspectiveMapping | Bonvision",
    "keywords": "PerspectiveMapping workflow Operator Renders the current scene to a texture and applies perspective mapping as a post-processing effect. Inputs & Outputs Properties Property Type Description ClearColor Placeholder Gets or sets the color used to clear the framebuffer before rendering. Destination Placeholder Gets or sets the coordinates of the four quadrangle vertices specifying the perspective transform. Relationships Namespace - BonVision.Environment Assembly - PerspectiveMapping.dll PerspectiveMapping"
  },
  "api/BonVision.Environment.PerspectiveView.html": {
    "href": "api/BonVision.Environment.PerspectiveView.html",
    "title": "Class PerspectiveView | Bonvision",
    "keywords": "PerspectiveView workflow Operator Specifies a perspective view, commonly used for 3D stimulus environments. Inputs & Outputs Properties Property Type Description Light Placeholder The position of the main point light. FieldOfView Placeholder The value of the camera field of view. Eye Placeholder Gets or sets the eye, or camera position, in the world coordinate frame. Target Placeholder Gets or sets the target position in the world coordinate frame. Up Placeholder Gets or sets a 3D vector specifying the up vector of the camera, in the world coordinate frame. Should not be parallel to the camera direction. NearClip Placeholder Gets or sets the distance to the near clip plane. FarClip Placeholder Gets or sets the distance to the far clip plane. Relationships Namespace - BonVision.Environment Assembly - PerspectiveView.dll PerspectiveView"
  },
  "api/BonVision.Environment.RenderHmd.html": {
    "href": "api/BonVision.Environment.RenderHmd.html",
    "title": "Class RenderHmd | Bonvision",
    "keywords": "RenderHmd workflow Operator Renders all currently stored draw commands into a head-mounted display. Each pass renders one eye of the stereo display. Inputs & Outputs Relationships Namespace - BonVision.Environment Assembly - RenderHmd.dll RenderHmd"
  },
  "api/BonVision.Environment.SphereMapping.html": {
    "href": "api/BonVision.Environment.SphereMapping.html",
    "title": "Class SphereMapping | Bonvision",
    "keywords": "SphereMapping workflow Operator Renders the current viewport to a cubemap texture which can be used for environmental mapping of physical screens around the origin. Inputs & Outputs Properties Property Type Description FaceSize Placeholder Gets or sets the texture size for each of the cubemap faces. If no value is specified, the size of the shader window in pixels is used. ClearColor Placeholder Gets or sets the color used to clear the framebuffer before rendering. Width Placeholder The optional width of the texture used for spherical mapping. Higher values reduce blurring but decrease performance. Height Placeholder The optional height of the texture used for spherical mapping. Higher values reduce blurring but decrease performance. RotationZ Placeholder The rotation of the cubemap about the z-axis. RotationY Placeholder The rotation of the cubemap about the y-axis. RotationX Placeholder The rotation of the cubemap about the x-axis. Relationships Namespace - BonVision.Environment Assembly - SphereMapping.dll SphereMapping"
  },
  "api/BonVision.Environment.ViewMapping.html": {
    "href": "api/BonVision.Environment.ViewMapping.html",
    "title": "Class ViewMapping | Bonvision",
    "keywords": "ViewMapping workflow Operator Renders the environment using a view direction vector map for each fragment in the current viewport. Inputs & Outputs Properties Property Type Description FileName Placeholder Gets or sets the name of the image file. Relationships Namespace - BonVision.Environment Assembly - ViewMapping.dll ViewMapping"
  },
  "api/BonVision.Environment.ViewWindow.html": {
    "href": "api/BonVision.Environment.ViewWindow.html",
    "title": "Class ViewWindow | Bonvision",
    "keywords": "ViewWindow workflow Operator Renders the environment from the perspective of a view window of the specified size, position and orientation relative to the origin. Inputs & Outputs Properties Property Type Description Width Placeholder The width of the viewing window, in metric units. Height Placeholder The height of the viewing window, in metric units. Rotation Placeholder The rotation vector describing the orientation of the viewing window. Translation Placeholder The translation vector describing the location of the viewing window, in metric units. Relationships Namespace - BonVision.Environment Assembly - ViewWindow.dll ViewWindow"
  },
  "api/BonVision.Environment.html": {
    "href": "api/BonVision.Environment.html",
    "title": "Namespace BonVision.Environment | Bonvision",
    "keywords": ""
  },
  "api/BonVision.FieldOfViewProperty.html": {
    "href": "api/BonVision.FieldOfViewProperty.html",
    "title": "Class FieldOfViewProperty | Bonvision",
    "keywords": "FieldOfViewProperty source Operator Inputs & Outputs /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } float /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } Observable float Properties Property Type Description Value float ValueXml float Relationships Namespace - BonVision Assembly - BonVision.dll Inheritance object FieldOfViewProperty"
  },
  "api/BonVision.Logging.EventLogger.html": {
    "href": "api/BonVision.Logging.EventLogger.html",
    "title": "Class EventLogger | Bonvision",
    "keywords": "EventLogger workflow Operator Creates and initializes a CSV file, and matching behavior subject, on which to log events. Inputs & Outputs Properties Property Type Description Name Placeholder The name of the subject on which events will be logged. FileName Placeholder Gets or sets the name of the output CSV file. Append Placeholder Gets or sets a value indicating whether data should be appended to the output file if it already exists. Overwrite Placeholder Gets or sets a value indicating whether the output file should be overwritten if it already exists. Suffix Placeholder Gets or sets the suffix used to generate file names. Relationships Namespace - BonVision.Logging Assembly - EventLogger.dll EventLogger"
  },
  "api/BonVision.Logging.FrameEventLogger.html": {
    "href": "api/BonVision.Logging.FrameEventLogger.html",
    "title": "Class FrameEventLogger | Bonvision",
    "keywords": "FrameEventLogger workflow Operator Creates and initializes a CSV file, and matching behavior subject, used to log events with frame timing. Inputs & Outputs Properties Property Type Description Name Placeholder The name of the subject on which events will be logged. Append Placeholder Gets or sets a value indicating whether data should be appended to the output file if it already exists. Overwrite Placeholder Gets or sets a value indicating whether the output file should be overwritten if it already exists. Suffix Placeholder Gets or sets the suffix used to generate file names. FileName Placeholder Gets or sets the name of the output CSV file. Relationships Namespace - BonVision.Logging Assembly - FrameEventLogger.dll FrameEventLogger"
  },
  "api/BonVision.Logging.LogEvent.html": {
    "href": "api/BonVision.Logging.LogEvent.html",
    "title": "Class LogEvent | Bonvision",
    "keywords": "LogEvent workflow Operator Logs a value into the specified common event stream. Inputs & Outputs Properties Property Type Description Format Placeholder Gets or sets the composite format string used to specify the output representation. Selector Placeholder Gets or sets a string used to specify the properties that will be included in the output representation. Name Placeholder Gets or sets the name of the shared subject. Relationships Namespace - BonVision.Logging Assembly - LogEvent.dll LogEvent"
  },
  "api/BonVision.Logging.html": {
    "href": "api/BonVision.Logging.html",
    "title": "Namespace BonVision.Logging | Bonvision",
    "keywords": ""
  },
  "api/BonVision.OptionalFloatProperty.html": {
    "href": "api/BonVision.OptionalFloatProperty.html",
    "title": "Class OptionalFloatProperty | Bonvision",
    "keywords": "OptionalFloatProperty source Operator Inputs & Outputs /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } float? /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } Observable float? Properties Property Type Description HasValue bool Value float? Relationships Namespace - BonVision Assembly - BonVision.dll Inheritance object OptionalFloatProperty"
  },
  "api/BonVision.Primitives.BonVisionResources.html": {
    "href": "api/BonVision.Primitives.BonVisionResources.html",
    "title": "Class BonVisionResources | Bonvision",
    "keywords": "BonVisionResources workflow Operator Loads mesh and shader resources for rendering primitive stimuli. Inputs & Outputs Relationships Namespace - BonVision.Primitives Assembly - BonVisionResources.dll BonVisionResources"
  },
  "api/BonVision.Primitives.DrawCheckerboard.html": {
    "href": "api/BonVision.Primitives.DrawCheckerboard.html",
    "title": "Class DrawCheckerboard | Bonvision",
    "keywords": "DrawCheckerboard workflow Operator Draws a parameterized checkerboard stimulus. Inputs & Outputs Properties Property Type Description NumberColumns Placeholder The number of columns in the checkerboard. NumberRows Placeholder The number of rows in the checkerboard. Phase Placeholder The contrast phase offset used to tile the checkerboard stimulus. Angle Placeholder The angle of the checkerboard stimulus. LocationX Placeholder Gets or sets the translation along the x-axis. LocationY Placeholder Gets or sets the translation along the y-axis. Layer Placeholder The optional drawing overlay priority. Lower numbers appear below higher numbers. ExtentX Placeholder The size of the checkerboard along the x-axis. ExtentY Placeholder The size of the checkerboard along the y-axis. Relationships Namespace - BonVision.Primitives Assembly - DrawCheckerboard.dll DrawCheckerboard"
  },
  "api/BonVision.Primitives.DrawCircle.html": {
    "href": "api/BonVision.Primitives.DrawCircle.html",
    "title": "Class DrawCircle | Bonvision",
    "keywords": "DrawCircle workflow Operator Draws a single colored circle. Inputs & Outputs Properties Property Type Description Diameter Placeholder The diameter of the circle. LocationX Placeholder Gets or sets the translation along the x-axis. LocationY Placeholder Gets or sets the translation along the y-axis. Layer Placeholder The optional drawing overlay priority. Lower numbers appear below higher numbers. ColorR Placeholder The red component of the circle color. ColorG Placeholder The green component of the circle color. ColorB Placeholder The blue component of the circle color. ColorA Placeholder The alpha, or opacity, component of the circle color. Relationships Namespace - BonVision.Primitives Assembly - DrawCircle.dll DrawCircle"
  },
  "api/BonVision.Primitives.DrawCircleArray.html": {
    "href": "api/BonVision.Primitives.DrawCircleArray.html",
    "title": "Class DrawCircleArray | Bonvision",
    "keywords": "DrawCircleArray workflow Operator Draws multiple colored circles using the specified position data array. Inputs & Outputs Properties Property Type Description Diameter Placeholder The diameter of individual circles. LocationX Placeholder Gets or sets the translation along the x-axis. LocationY Placeholder Gets or sets the translation along the y-axis. Layer Placeholder The optional drawing overlay priority. Lower numbers appear below higher numbers. ColorR Placeholder The red component of the circle color. ColorG Placeholder The green component of the circle color. ColorB Placeholder The blue component of the circle color. ColorA Placeholder The alpha, or opacity, component of the circle color. PositionData Placeholder The source containing the position data to draw. The array data should contain a sequence of 2D position values. Relationships Namespace - BonVision.Primitives Assembly - DrawCircleArray.dll DrawCircleArray"
  },
  "api/BonVision.Primitives.DrawGratings.html": {
    "href": "api/BonVision.Primitives.DrawGratings.html",
    "title": "Class DrawGratings | Bonvision",
    "keywords": "DrawGratings workflow Operator Draws parameterized 2D sinewave gratings. Inputs & Outputs Properties Property Type Description Angle Placeholder The angle of the grating stimulus. LocationX Placeholder Gets or sets the translation along the x-axis. LocationY Placeholder Gets or sets the translation along the y-axis. Layer Placeholder The optional drawing overlay priority. Lower numbers appear below higher numbers. ExtentX Placeholder The size of the grating stimulus in the x-axis. ExtentY Placeholder The size of the grating stimulus in the y-axis. TemporalFrequency Placeholder The sliding speed of the grating stimulus, in cycles per second. SpatialFrequency Placeholder The spatial frequency of the gratings, in cycles per degree. Phase Placeholder The optional phase offset of the grating stimulus, in degrees. DutyCycle Placeholder The duty cycle used to modulate square wave gratings. SquareWave Placeholder A value specifying whether to use a sine or square wave function as a basis for the stimulus. Contrast Placeholder The contrast of the grating stimulus, where zero is no contrast, and one is maximum contrast. Radius Placeholder The normalized radius of the clipping mask applied to the stimulus. Aperture Placeholder The optional variance of the gaussian mask applied to the stimulus. A value of zero specifies that no mask should be applied. Opacity Placeholder The normalized opacity of the stimulus. Zero is fully transparent, and one is fully opaque. Relationships Namespace - BonVision.Primitives Assembly - DrawGratings.dll DrawGratings"
  },
  "api/BonVision.Primitives.DrawImage.html": {
    "href": "api/BonVision.Primitives.DrawImage.html",
    "title": "Class DrawImage | Bonvision",
    "keywords": "DrawImage workflow Operator Draws an affine transformed 2D image. Inputs & Outputs Properties Property Type Description Angle Placeholder The angle of the image. TextureName Placeholder The name of the texture to display. LocationX Placeholder Gets or sets the translation along the x-axis. LocationY Placeholder Gets or sets the translation along the y-axis. Layer Placeholder The optional drawing overlay priority. Lower numbers appear below higher numbers. ExtentX Placeholder The size of the image along the x-axis. ExtentY Placeholder The size of the image along the x-axis. ScaleX Placeholder The texture scale factor on the x-axis. ScaleY Placeholder The texture scale factor on the y-axis. ShiftX Placeholder The texture shift on the x-axis. ShiftY Placeholder The texture shift on the y-axis. Relationships Namespace - BonVision.Primitives Assembly - DrawImage.dll DrawImage"
  },
  "api/BonVision.Primitives.DrawModel.html": {
    "href": "api/BonVision.Primitives.DrawModel.html",
    "title": "Class DrawModel | Bonvision",
    "keywords": "DrawModel workflow Operator Draws a transformed 3D model stimulus. Inputs & Outputs Properties Property Type Description TranslationX Placeholder Gets or sets the translation along the x-axis. TranslationY Placeholder Gets or sets the translation along the y-axis. TranslationZ Placeholder Gets or sets the translation along the z-axis. ScaleX Placeholder Gets or sets the scale factor for the x-axis. ScaleY Placeholder Gets or sets the scale factor for the y-axis. ScaleZ Placeholder Gets or sets the scale factor for the z-axis. MeshName Placeholder Gets or sets the name of the mesh geometry to draw. Ambient Placeholder The amount and color of the ambient light reflected by the material. Diffuse Placeholder The amount and color of the diffuse light reflected by the material. Specular Placeholder The amount and color of the specular light reflected by the material. SpecularExponent Placeholder The exponent used to compute the specular response of the material. RotationZ Placeholder The rotation about the z-axis. RotationY Placeholder The rotation about the y-axis. RotationX Placeholder The rotation about the x-axis. Relationships Namespace - BonVision.Primitives Assembly - DrawModel.dll DrawModel"
  },
  "api/BonVision.Primitives.DrawModelArray.html": {
    "href": "api/BonVision.Primitives.DrawModelArray.html",
    "title": "Class DrawModelArray | Bonvision",
    "keywords": "DrawModelArray workflow Operator Draws multiple model instances using per-instance 4x3 transform matrix data array. Inputs & Outputs Properties Property Type Description MeshName Placeholder Gets or sets the name of the mesh geometry to draw. TranslationX Placeholder Gets or sets the translation along the x-axis. TranslationY Placeholder Gets or sets the translation along the y-axis. TranslationZ Placeholder Gets or sets the translation along the z-axis. ScaleX Placeholder Gets or sets the scale factor for the x-axis. ScaleY Placeholder Gets or sets the scale factor for the y-axis. ScaleZ Placeholder Gets or sets the scale factor for the z-axis. Ambient Placeholder The amount and color of the ambient light reflected by the material. Diffuse Placeholder The amount and color of the diffuse light reflected by the material. Specular Placeholder The amount and color of the specular light reflected by the material. SpecularExponent Placeholder The exponent used to compute the specular response of the material. RotationZ Placeholder The rotation about the z-axis. RotationY Placeholder The rotation about the y-axis. RotationX Placeholder The rotation about the x-axis. Relationships Namespace - BonVision.Primitives Assembly - DrawModelArray.dll DrawModelArray"
  },
  "api/BonVision.Primitives.DrawQuad.html": {
    "href": "api/BonVision.Primitives.DrawQuad.html",
    "title": "Class DrawQuad | Bonvision",
    "keywords": "DrawQuad workflow Operator Draws a single colored quad. Inputs & Outputs Properties Property Type Description Angle Placeholder The angle of the quad. LocationX Placeholder Gets or sets the translation along the x-axis. LocationY Placeholder Gets or sets the translation along the y-axis. Layer Placeholder The optional drawing overlay priority. Lower numbers appear below higher numbers. ExtentX Placeholder The size of the quad along the x-axis. ExtentY Placeholder The size of the quad along the y-axis. ColorR Placeholder The red component of the quad color. ColorG Placeholder The green component of the quad color. ColorB Placeholder The blue component of the quad color. ColorA Placeholder The alpha, or opacity, component of the quad color. Relationships Namespace - BonVision.Primitives Assembly - DrawQuad.dll DrawQuad"
  },
  "api/BonVision.Primitives.DrawSceneModel.html": {
    "href": "api/BonVision.Primitives.DrawSceneModel.html",
    "title": "Class DrawSceneModel | Bonvision",
    "keywords": "DrawSceneModel workflow Operator Draws a transformed 3D scene stimulus. Inputs & Outputs Properties Property Type Description TranslationX Placeholder Gets or sets the translation along the x-axis. TranslationY Placeholder Gets or sets the translation along the y-axis. TranslationZ Placeholder Gets or sets the translation along the z-axis. ScaleX Placeholder Gets or sets the scale factor for the x-axis. ScaleY Placeholder Gets or sets the scale factor for the y-axis. ScaleZ Placeholder Gets or sets the scale factor for the z-axis. RotationZ Placeholder The rotation about the z-axis. RotationY Placeholder The rotation about the y-axis. RotationX Placeholder The rotation about the x-axis. SceneName Placeholder Gets or sets the name of the scene to update. Relationships Namespace - BonVision.Primitives Assembly - DrawSceneModel.dll DrawSceneModel"
  },
  "api/BonVision.Primitives.DrawText.html": {
    "href": "api/BonVision.Primitives.DrawText.html",
    "title": "Class DrawText | Bonvision",
    "keywords": "DrawText workflow Operator Draws affine transformed multi-line text using the specified style. Inputs & Outputs Properties Property Type Description Text Placeholder Gets or sets the text to draw. Font Placeholder Gets or sets the font style used to render the text strokes. Alignment Placeholder Gets or sets the horizontal alignment of the text. LineAlignment Placeholder Gets or sets the vertical alignment of the text. TextRenderingHint Placeholder Gets or sets the rendering mode used for the text strokes. Color Placeholder Gets or sets the color of the text. ExtentX Placeholder The size of the text along the x-axis. ExtentY Placeholder The size of the text along the y-axis. Destination Placeholder Gets or sets the optional region in which to draw the text. By default the box will fill the entire image. Size Placeholder Gets or sets the size of the canvas. Angle Placeholder The angular orientation of the text. LocationX Placeholder Gets or sets the translation along the x-axis. LocationY Placeholder Gets or sets the translation along the y-axis. Layer Placeholder The optional drawing overlay priority. Lower numbers appear below higher numbers. Relationships Namespace - BonVision.Primitives Assembly - DrawText.dll DrawText"
  },
  "api/BonVision.Primitives.DrawTexturedModel.html": {
    "href": "api/BonVision.Primitives.DrawTexturedModel.html",
    "title": "Class DrawTexturedModel | Bonvision",
    "keywords": "DrawTexturedModel workflow Operator Draws a textured and transformed 3D model stimulus. Inputs & Outputs Properties Property Type Description TranslationX Placeholder Gets or sets the translation along the x-axis. TranslationY Placeholder Gets or sets the translation along the y-axis. TranslationZ Placeholder Gets or sets the translation along the z-axis. ScaleX Placeholder Gets or sets the scale factor for the x-axis. ScaleY Placeholder Gets or sets the scale factor for the y-axis. ScaleZ Placeholder Gets or sets the scale factor for the z-axis. MeshName Placeholder Gets or sets the name of the mesh geometry to draw. Ambient Placeholder The amount and color of the ambient light reflected by the material. Diffuse Placeholder The amount and color of the diffuse light reflected by the material. Specular Placeholder The amount and color of the specular light reflected by the material. SpecularExponent Placeholder The exponent used to compute the specular response of the material. RotationZ Placeholder The rotation about the z-axis. RotationY Placeholder The rotation about the y-axis. RotationX Placeholder The rotation about the x-axis. Relationships Namespace - BonVision.Primitives Assembly - DrawTexturedModel.dll DrawTexturedModel"
  },
  "api/BonVision.Primitives.DrawTexturedModelArray.html": {
    "href": "api/BonVision.Primitives.DrawTexturedModelArray.html",
    "title": "Class DrawTexturedModelArray | Bonvision",
    "keywords": "DrawTexturedModelArray workflow Operator Draws multiple textured model instances using per-instance 4x3 transform matrix data array. Inputs & Outputs Properties Property Type Description MeshName Placeholder Gets or sets the name of the mesh geometry to draw. TranslationX Placeholder Gets or sets the translation along the x-axis. TranslationY Placeholder Gets or sets the translation along the y-axis. TranslationZ Placeholder Gets or sets the translation along the z-axis. ScaleX Placeholder Gets or sets the scale factor for the x-axis. ScaleY Placeholder Gets or sets the scale factor for the y-axis. ScaleZ Placeholder Gets or sets the scale factor for the z-axis. Ambient Placeholder The amount and color of the ambient light reflected by the material. Diffuse Placeholder The amount and color of the diffuse light reflected by the material. Specular Placeholder The amount and color of the specular light reflected by the material. SpecularExponent Placeholder The exponent used to compute the specular response of the material. RotationZ Placeholder The rotation about the z-axis. RotationY Placeholder The rotation about the y-axis. RotationX Placeholder The rotation about the x-axis. Relationships Namespace - BonVision.Primitives Assembly - DrawTexturedModelArray.dll DrawTexturedModelArray"
  },
  "api/BonVision.Primitives.DrawVideo.html": {
    "href": "api/BonVision.Primitives.DrawVideo.html",
    "title": "Class DrawVideo | Bonvision",
    "keywords": "DrawVideo workflow Operator Draw and update an affine transformed 2D video texture. Inputs & Outputs Properties Property Type Description TextureName Placeholder The name of the texture to display. PlaybackRate Placeholder Gets or sets the rate at which to playback the sequence. A value of zero means the native frame rate will be used. Loop Placeholder Gets or sets a value indicating whether the video should loop when the end of the file is reached. Angle Placeholder The angle of the image. ExtentX Placeholder The size of the image along the x-axis. ExtentY Placeholder The size of the image along the x-axis. LocationX Placeholder Gets or sets the translation along the x-axis. LocationY Placeholder Gets or sets the translation along the y-axis. ScaleX Placeholder The texture scale factor on the x-axis. ScaleY Placeholder The texture scale factor on the y-axis. ShiftX Placeholder The texture shift on the x-axis. ShiftY Placeholder The texture shift on the y-axis. Layer Placeholder The optional drawing overlay priority. Lower numbers appear below higher numbers. Relationships Namespace - BonVision.Primitives Assembly - DrawVideo.dll DrawVideo"
  },
  "api/BonVision.Primitives.ParameterRange.html": {
    "href": "api/BonVision.Primitives.ParameterRange.html",
    "title": "Class ParameterRange | Bonvision",
    "keywords": "ParameterRange workflow Operator Generates a linear range of values between min and max. Inputs & Outputs Properties Property Type Description RangeMin Placeholder Gets or sets the lower bound of the range of values after the rescale operation. RangeMax Placeholder Gets or sets the upper bound of the range of values after the rescale operation. Count Placeholder The number of parameter values to generate. Relationships Namespace - BonVision.Primitives Assembly - ParameterRange.dll ParameterRange"
  },
  "api/BonVision.Primitives.RangeAnimation.html": {
    "href": "api/BonVision.Primitives.RangeAnimation.html",
    "title": "Class RangeAnimation | Bonvision",
    "keywords": "RangeAnimation workflow Operator Animates a linear range of values between min and max at the specified cycles per second. Inputs & Outputs Properties Property Type Description Duration Placeholder The length of the animation, in seconds. RangeBegin Placeholder Gets or sets the lower bound of the range of values after the rescale operation. RangeEnd Placeholder Gets or sets the upper bound of the range of values after the rescale operation. Relationships Namespace - BonVision.Primitives Assembly - RangeAnimation.dll RangeAnimation"
  },
  "api/BonVision.Primitives.html": {
    "href": "api/BonVision.Primitives.html",
    "title": "Namespace BonVision.Primitives | Bonvision",
    "keywords": ""
  },
  "api/BonVision.RotationProperty.html": {
    "href": "api/BonVision.RotationProperty.html",
    "title": "Class RotationProperty | Bonvision",
    "keywords": "RotationProperty source Operator Inputs & Outputs /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } Point3d /* Fixed width for larger screens */ .operator-table { width: 600px; max-width: 100%; /* Ensures the table scales down on smaller screens */ margin: 0 auto; /* Centers the table horizontally */ border: 0; table-layout: fixed; padding: 0; margin-bottom: 1rem; } .outer-cell, .nested-table, .arrow-cell, .text-cell { border: 0; margin: 0; vertical-align: middle; } .outer-cell{ padding: 0 !important; } .nested-table{ table-layout: fixed; } .text-cell{ width: 70%; border: 1px solid !important; /* Fix top and bottom border dissappearing due to */ border-color: var(--bs-border-color) !important; /* Fix color dissappearing */ } .arrow-cell{ width: 30%; text-align: right; } Observable Point3d Properties Property Type Description Value Point3d ValueXml Point3d Relationships Namespace - BonVision Assembly - BonVision.dll Inheritance object RotationProperty"
  },
  "api/BonVision.html": {
    "href": "api/BonVision.html",
    "title": "Namespace BonVision | Bonvision",
    "keywords": ""
  },
  "api_landing/api_landing.html": {
    "href": "api_landing/api_landing.html",
    "title": "BonVision node library | Bonvision",
    "keywords": "BonVision node library There are 5 types of BonVision nodes: I. Primitives These are the nodes that define fundamental visual stimulus characteristics. II. Environment These define the aspects of the visual display devices. III. Collections These are nodes that define visual stimuli that comprise a collection of Primitives. IV. Logging These are nodes to help keep log of stimulus parameters for analysis V. Generic These are generic helper nodes"
  },
  "articles/basic-workflow.html": {
    "href": "articles/basic-workflow.html",
    "title": "Overview | Bonvision",
    "keywords": "Overview There are five basic sections to making a workflow in BonVision. These sections will be covered in more detail in individual articles which you can access from the sidebar. flowchart TD A(Create Window) --> B(Drawing Region) --> C(Draw Stimuli) --> D(Map Stimuli*) --> E(Define Display*) Note Map Stimuli and Define Display steps are optional and can be skipped when prototyping Create Window All BonVision workflows need to start by creating a display window and loading the essential BonVision resources. If additional resources such as 3D models and textures are required, load them at this step using the optional SceneResources and TextureResources node. Note Copy the workflows below directly into Bonsai by clicking the copy button on the top right of the container to test them out. Drawing Region This defines which region of visual space is used for the visual world as well as the units for the parameters (sizes/locations) that stimuli are drawn with. For the purpose of prototyping stimuli, use NormalisedView. Draw Stimuli This is where you generate all the aspects of the visual environment. Note At this point you have all the basic parts necessary to create and prototype visual environments. The workflow below encapsulates all these steps and draws a simple black and white circle. Copy it into Bonsai and try it out! Map Stimuli (optional) This is where 2D stimuli are rendered onto a surface for display in 3D environments using the SphereMapping operator. More information can be found in the Display Environments. Define Display (optional) Here we define the parameters of the display system by adding a ViewingWindow (which are windows into the visual environment) and a DrawViewport (for configuring 1 or more monitors) operator. Video Walkthrough"
  },
  "articles/community/community.html": {
    "href": "articles/community/community.html",
    "title": "Community | Bonvision",
    "keywords": "Community Online Resources Twitter: Follow us @BonVision_ YouTube Channel: Learning materials and demos Issues: Report issues on Bonvision Github Forums: Bonsai Github Discussions (We will be using the Bonsai github forum for BonVision discussions, as some issues can be overlapping and related to the Bonsai framework rather than the specifics of BonVision) Bonsai: Learn more about Bonsai, Bonsai Documentation Example Scripts Examples: A collection of example workflows for Bonvision Current User Groups Saleem lab, UCL, London Solomon lab, UCL, London International Brain Lab Ranson Lab, UAB/UIC, Barcelona, Spain Get Involved If you would like to help us develop additional features for BonVision or add to the database of example scripts, please get in touch with us at: aman dot saleem at ucl.ac.uk or g dot lopes at neurogears.org"
  },
  "articles/create-window.html": {
    "href": "articles/create-window.html",
    "title": "Create Window | Bonvision",
    "keywords": "Create Window The CreateWindow operator creates an OpenGL window where all the stimuli will be rendered and contains many properties for adjusting the visual environment. The ClearColor property specifies the background color of the visual environment. The DisplayDevice property controls which monitor the window will be displayed on (for instance if you have multiple monitors). The TargetRenderFrequency property controls how fast the stimuli are rendered (by default 60fps). The TargetUpdateFrequency property by default is set to the same as the TargetRenderFrequency but can actually be set higher (for instance 120fps) (useful if you have a high refresh rate monitor but cannot render at the higher TargetRenderFrequency). The WindowBorderproperty can be used to hide the window border or make it resizable (for instance, if you want the window to span multiple displays) The WindowState property controls how the the window will be displayed (for instance, you can make it full-screen) Video Walkthrough"
  },
  "articles/define-display.html": {
    "href": "articles/define-display.html",
    "title": "Define Display | Bonvision",
    "keywords": "Define Display ViewWindow ViewWindow are windows into the virtual environment that is being rendered. To better illustrate how viewing windows interact with the visual environment, this is an example of the same stimulus (mapped onto a sphere) viewed through different viewing windows. The first two rows are from a top down perspective, with the red dot indicating the subject and the lines indicating the placement of the viewing window. The images on the right hand side show the final image as viewed from those viewing windows. Each ViewWindow must be accompanied by a DrawViewport operator. Additional displays can be defined by adding multiple ViewingWindow/DrawViewport nodes. DrawViewport The DrawViewport operator draws the ViewWindow to a display and provides additional options for positioning the ViewWindow on a display. This example workflow illustrates how we can combine the ViewWindow and DrawViewport operators to flexibly position different views (for instance, when we have two monitors side by side). A single checkboard is drawn in the visual environment and two ViewWindows are positioned side by side (by adjusting the X-axis variable in the Translation property). Then we draw the two views to two displays. Video Walkthrough Post-processing Operators (optional) Bonvision comes with post-processing operators to correct for various distortions in the final display of the image (for instance, when using a projector in conjunction with a mirror/lens or projecting on non-uniform surfaces). These operators would be placed between the ViewWindow and DrawViewport operator. PerspectiveMapping The PerspectiveMapping operator can be used to correct distortions when projecting displays on the walls of an rectangular arena. One would specify 4 ViewWindows, one for each wall, and then specify a PerspectiveMapping for each view window to transform the view before attaching a DrawViewport operator. An example implementation can be found at https://groups.google.com/g/bonsai-users/c/WV7V57vlSAk/m/XjQPqCJkCAAJ. MeshMapping The MeshMapping operator is best used to correct distortions when projecting displays on a demispherical dome. As the process is more complicated, check out the mesh mapping calibration article for more information how to measure and calibrate this operator. GammaCorrection The GammaCorrection operator applies simple intensity mapping of the three colors, to make sure the stimuli are linear. It uses a simple LUT (Look-up-table), for Red, Green and Blue. Check out the gamma calibration article for more information on how to measure and calibrate this operator. Other nodes to document (under construction) ViewMapping"
  },
  "articles/demos/2AFC-demo.html": {
    "href": "articles/demos/2AFC-demo.html",
    "title": "Vision Psychophysics - 2AFC | Bonvision",
    "keywords": "Vision Psychophysics - 2AFC This is a demo of a simple orientation discrimination vision psychophysics task using a two-alternative forced choice paradigm. You can copy and paste the workflow below directly into the Bonsai window by clicking on the copy button on the top right of the container. For a full tutorial on how to build this workflow, visit the Vision Psychophysics tutorial on the Bonsai documentation website. Usage After pressing run, two gratings will appear on screen in quick succession, followed by a question A or B. Press the Left keyboard arrow key if the first grating A has a more clockwise orientation (to the right) and the Right keyboard arrow key if the 2nd grating B has a more clockwise orientation. A green square will appear onscreen to signify if the choice made was True and red for False."
  },
  "articles/demos/AR-demo.html": {
    "href": "articles/demos/AR-demo.html",
    "title": "Augmented Reality | Bonvision",
    "keywords": "Augmented Reality This is a demo of a simple augmented reality, where there are four objects placed in front, and the view of the object is dependent on the observer’s position. You can download this demo from the demos folder in the examples repository. The demo is called ClosedLoop. The workflow is encapsulated below which you can copy into your Bonsai Window. Note The workflow still requires the custom Models folder which can be downloaded above. Usage This demo shows how to construct, render and interact with a more complicated environment, as you might in ‘augmented reality’. After pressing run, several objects (‘models’) appear on the floor of a 3D environment, one of which is rotating around its core. The downloaded program listens to the webcam installed on your computer (if present) and tracks the position of a bright light source (like your cell phone’s flashlight). You can move through this environment by moving the flashlight towards and away from the webcam, and/or from side-to-side – your view of the scene should change as you move. Below is an example of what part of the visual display looks like during an experiment."
  },
  "articles/demos/LoomingSweeping-demo.html": {
    "href": "articles/demos/LoomingSweeping-demo.html",
    "title": "Looming/Sweeping Stimulus | Bonvision",
    "keywords": "Looming/Sweeping Stimulus These are demos of looming and sweeping visual stimuli that are similar to that used in Yilmaz et al., 2014 and Franceschi et al., 2016. You can copy and paste the workflows below directly into the Bonsai window by clicking on the copy button on the top right of the container. Looming Stimulus Usage Just hit Start in the menu. Press the space bar to initate the looming stimulus. You can change the Duration and RangeEnd property in the RangeAnimation operator to control the size and speed of the looming disk. To control how long the stimulus persists, change the DueTime property in the Timer node connected to the TakeUntil operator. Sweeping Stimulus Usage Just hit Start in the menu. Press the space bar to initate the looming stimulus. You can change the Duration property in the RangeAnimation operator to control the speed of the sweep. Video Walkthrough For an indepth walkthrough about how the demo works (with additional details), you can refer to this Bonsai Live Coding session."
  },
  "articles/demos/VR-demo.html": {
    "href": "articles/demos/VR-demo.html",
    "title": "Virtual Reality | Bonvision",
    "keywords": "Virtual Reality This is a demo of creating a simple VR corridor (similar to Saleem et al., Nature, 2018). You can download this demo from the demos folder in the examples repository. The demo is called CorridorVR. The workflow is encapsulated below which you can copy into your Bonsai Window. Note The workflow still requires the custom Textures folder which can be downloaded above. Usage Just hit Start in the menu. You can move through the VR by using the scroll wheel of the mouse. Once you reach the end of the corridor, you are teleported back to the start after a short interval. Here is how the output of this looks like:"
  },
  "articles/display-environment-basics.html": {
    "href": "articles/display-environment-basics.html",
    "title": "Display Environments | Bonvision",
    "keywords": "Display Environments Visual neuroscience is almost always carried out in eye-centric coordinates, which defines stimuli in terms of visual angle subtended at the eye. This helps keep the definition of the image that reaches the retina consistent. However, visual displays work in pixel coordinates (with specific physical characteristics) and to draw accurate stimuli one has to calculate the conversion between the two coordinate frames. This requires a new transform function to be calculated for any display, and few programs are available to help with this. In the following sections we describe the main assumptions and design decisions in BonVision for dealing with a broad family of visual stimuli, both 2D and 3D. Environmental mapping One of the major goals for BonVision was to unify the specification of both 2D and 3D visual environments into a common representation that would allow sharing experiments across multiple display configurations, including domes, toruses, display grids and other geometrical arrangements. To achieve this, the main design decision was to decouple the Display environment from the Stimulus Generation logic. This allows users of BonVision to write tasks in standard units (either degrees of visual field for 2D or metric units for 3D), and then run them unmodified on any correctly calibrated rig. We use cube mapping as a way to efficiently specify the entire surrounding environment of an experimental subject, both for 2D and 3D environments. In this technique, 6 different faces of a cube, each covering exactly a 90º field of view volume, are combined to describe the entire 360º environment (a.k.a. a skybox): At runtime, each screen becomes a window that looks out into that surrounding environment, with each pixel uniquely specifying a direction vector out into the world. In a cubemap, this direction vector is used to sample the correct pixels from the cubemap textures, therefore projecting onto the screen the corresponding portion of the visual field. Once the cube mapping rendering pipeline is in place, we can very efficiently generate an arbitrary number of projections into the visual space for each display in the experiment. The remaining challenge is then how to generate the 6 faces of the cubemap in a way that accurately represents the visual field surrounding the subject. 3D Stimuli For 3D scenes, there is a straightforward solution: render the visual scene once for each face of the cube, with a perspective 90º field of view, as seen from the observer. Each rendered perspective will fill exactly one face of the cube. For example: Using the cube mapping pipeline, one can then point a viewing window at any direction and get a correct rendition of the surrounding environment at those pixels: 2D Stimuli For 2D scenes, such as those containing gabor patches, checkerboards, gratings, random dots and so on, we would like to specify our environments in an orthonormal space, where X and Y represent longitude and latitude, respectively, in degrees of visual field. For example, below is a checkerboard stimulus covering 100 degrees of visual field horizontally and vertically, where each square subtends 10 degrees: To correctly display this environment using the cubemap rendering approach, we need to map this 2D orthonormal space into a 3D spherical environment, which we can then cubemap the same way as for 3D environments. This is essentially the reverse cartographer's problem of specifying a map projection of the sphere onto a planar surface. Unfortunately, there is no perfect way of mapping a sphere onto a plane. Different transformations will preserve different features, e.g. area-preserving, distance-preserving, shape-preserving, etc, and in general we will always need to tradeoff one against the other. For example, a popular mapping is the equirectangular, or cylindrical mapping: This projection features asymmetrical distortion in both axes, which preserves the meridian lines as vertical lines in the mapping, and introduces distortion around the poles: Other projections remove the distortion at the poles by distributing it across different portions of the image. For example, the icosphere tiles the surface using multiple triangle subdivisions: The disadvantage is that the arrangement of the planar mapping is not orthonormal anymore, especially at the poles. At the moment BonVision makes use of a cylindrical projection, but improvements are being discussed at the moment to support different kinds of spherical mapping strategies to cover a larger number of cases. More details on spherical mapping from the point of view of modelling software Virtual Reality vs Augmented Reality Shawn's note - This needs more clarity as they both seem to be the same (fixed window/eye, objects/environment move around). Virtual Reality (VR) VR can be easily defined as a situation where the eye, and the screens (windows) are fixed positions, while all the objects (or VR environment) moves across the eye. Example rendering to be added here For Augmented Reality (AR) This is a scenario where, generally, the screens remain in a fixed position and the animal can move around. Since we have an eye-centric coordinate frame, the objects and the screen move around to generate an AR. Example rendering to be added here"
  },
  "articles/display-position-calibration.html": {
    "href": "articles/display-position-calibration.html",
    "title": "Display Position | Bonvision",
    "keywords": "Display Position The workflows in this article can be found here. Display Position Calibration BonVision is fundamentally based on creating stimuli that are true to the experimenter's definition of the visual environment around a subject, and display devices (monitors/projectors) are merely windows into this environment. Therefore, it is important to know which part of the environment the displays are looking into. The position of the visual field that the display is looking into is defined by the parameters in the ViewPort node. Specifically, the parameters: ___, ____, ____, & ____. There are two ways of calibrating the position of a display in BonVision: 1. Old school with ruler and protractor Measure the physical distances and angles. This can get a little tricky with getting accurate measurements of angle. However, if you have a method to measure this, or are happy with approximate values, these are the measurements you would need: The size of the display in azimuth and elevation The distance of the bottom of the screen from the subject's position The angles of the __ __ of the monitor from the subject's position 2. Automated calibration with camera We developed these workflows to enable easy and effective calibration of display position. Conceptually, this is done using a calibrated camera (we provide a workflow to calibrate here) and Aruco markers to identify the 3D coordinates of the display relative to the subject. The workflow identifies the Aruco patterns on the display and in the subject's position, using a calibrated camera, and automatically calculates the display's position. This automatic calibration has three workflow associated with it (each of them is expanded on below): A. Measuring camera intrinsics B. Show an Aruco image on the display C. Calibrate the screen position NOTE: To make it convenient, we have the option of calibrating the display by using your phone camera. You would need to take pictures of the setup as described below and upload the images on a system running Bonsai. A. Measuring camera intrinsics This workflow is to calibrate the intrinsic properties of the camera-lens combination, using standardized OpenCV formats. If you have previously calibrated the camera, you can simply save the value in the OpenCV format and link the function C (below) to that file. Alternatively, you will need to run this program. Running it displays a checkerboard pattern on the screen. (You can also print a checkboard patter of known size). Once it is displayed in the screen, measure the size a unit square and enter it under __ __ After that you will have to take pictures of the checkerboard pattern from different camera viewing angles. In the workflow, an image can be taken by hitting the spacebar. As a standard, we use 7 images (illustrated with figures below): from the front of the pattern from the Left from the Right from below the pattern from above from the top, right corner from the bottom left corner B. Measure display size using a Marker We again use an Aruco Marker to define the size of the display. The workflow __ __ displays a marker in the centre of the screen. One can then adjust the size of the marker by using the up/down keys. What we would like it to match the marker size with that of the one in the subject's position. We can do this by just measuring the two of them, or placing the paper over the screen and ensureing that they are the same size (there is often sufficient transparency on the paper to be able to do this. If not, go greener and use thinner paper in general). This output a display size that can be verified by measuring the actual dimensions of the screen. C. Calibrate the screen position We would need to have one Aruco marker on the centre of the display and one at the positon of the subject. The latter is ideally a print out of a known size. Once these are displayed, we just need them to be viewed simultaneously through the camera and run the workflow which generates the calibrated position values. As Aruco markers are directional, we have chosen to use Acuro marker Original #45 (shown below), and the marker need to be placed such that the thin side is looking in the direction that the subject is looking. Take an picture of the setup when the two markers are visible and run the workflow. Note: Make sure that there are just the two markers within the image. Multiple displays: These would have to be individually calibrated at the moment."
  },
  "articles/draw-stimuli.html": {
    "href": "articles/draw-stimuli.html",
    "title": "Draw Stimuli | Bonvision",
    "keywords": "Draw Stimuli Bonvision comes with a set of operators/primitives to draw basic shapes, display images and video, render common visual neuroscience stimuli, and display complex scenes and 3d models. The starting point to test these out is a basic workflow (which was covered in the overview section). Basic primitives Using these primitives are straightforward, there are properties to change the location as well as the size and color of the element being drawn. Images and video primitives In order to display images and videos, they have to be first loaded as a resource during the Create Section portion of the workflow using the TextureResources operator. Double click the TextureResourcesoperator and add the image as a ImageTexture or VideoTexture. BonVision also provides a way to display an image from a set of images using an ImageSequence. To do so, package the set of images as a video file and load them into the TextureResources operator as an ImageSequence. We can then select from the images to display by using a BindTexture operator in front of the DrawImage operator to choose which index/frame of the video we want to display. In this example workflow, pressing the spacebar samples from a random number distribution to select a random image to display. Video Walkthrough Neuroscience primitives Bonvision also comes with a set of primitives for drawing common visual neuroscience stimuli. These neuroscience primitives are covered in more detail in the Neuroscience Stimuli article. 3D Model and Scene primitives DrawModel DrawModel is used to display 3D models without textures. DrawModel supports 3D models in the .obj file format. The models have to be first loaded as a resource during the Create Section portion of the workflow using the MeshResources operator (which loads mesh or geometry resources). To try the example workflow out, download a 3D model (such as the icosphere) from the Bonvision Examples Repository. Double click on the MeshResources operator and add the downloaded model as a TexturedModel, giving it a name like icosphere. In the DrawModel node, select the model icosphere under the MeshName property DrawTexturedModel DrawTexturedModel is used to display 3D models with textures. To use DrawTexturedModel, during the Create Section portion of the workflow the model needs to be loaded using using the MeshResources operator and the texture needs to be loaded using the TextureResources operator (which loads image or video resources). To try the example workflow out, download the 3D model TextureSphere and the BlueMarble.jpg from the Bonvision Examples Repository. Double click on the MeshResources operator and add the downloaded model as a TexturedModel. Double click on the TextureResources operator and add the downloaded texture as a ImageTexture. Before drawing the TexturedModel, add a BindTexture operator with the following parameters: ShaderName - TexturedModel TextureName - BlueMarble TextureTarget - Texture2D Lastly add the DrawTexturedModel operator after the BindTexture operator, choosing the TextureSphere model under the MeshName property. Note A common use case for this node would be to create walls for VR environments with different textures and shapes. Bonvision comes with a inbuilt mesh called Plane that can be used for this purpose (it does not need to be loaded first with the MeshResources operator). Check out the VR corridor under the Demo section of the website for a walkthrough. DrawSceneModel DrawSceneModel is used to display complex 3D scenes and models. To use the DrawSceneModel, during the Create Section portion of the workflow the scene needs to be loaded using using the SceneResources operator.The SceneResources operator uses the Open Asset Import Library (assimp) for loading scene files. Warning Technically all the file formats supported by assimp should work, but certain custom properties (such as inbuilt animations/fancy custom effects/skeletons) are not supported. Loading Blender .blend files tends to be finicky and newer Blender version files are not supported. We recommend loading .obj files for now due to their simplicity. Warning For complex scenes, .obj files often come packaged with a .mtl material file that contains definitions for how to shade/color the 3D model. The SceneResources operator will load both at once if it can find it. Technically, the .mtl file isn't a texture file, so when choosing a shader to render the model with, we choose the Model shader. To try this example workflow out, download this 3D model IronMan. Make sure both the .obj and .mtl file are in the same location. Double click on the SceneResources operator and add the downloaded model as a SceneConfiguration. Choose Model for the shader. Adjust the properties of the PerspectiveView to view large 3D scenes and adjust the orientation if they appear misaligned."
  },
  "articles/drawing-region.html": {
    "href": "articles/drawing-region.html",
    "title": "Drawing Region | Bonvision",
    "keywords": "Drawing Region The drawing views define which region of visual space is used for the visual world as well as the units for the parameters (sizes/locations) that stimuli are drawn with. Note This can be larger than the actual region used. All drawing views accept a RenderFrame as input and a DrawX stimuli as output as shown in the basic workflow below. 2D Stimuli NormalizedView NormalizedView is the default view for rapid prototyping of 2D stimuli. This view scales the screen from -1 to 1 on both axes and has no properties to adjust. Stimuli drawn will have parameters (eg, sizes, locations) in terms of proportions of the screen size, in contrast to OrthographicView. In this example workflow, we have drawn a circle with a diameter of 1. Since the screen size is scaled from -1 to 1 on both axes, that results in a circle that takes up half the screen in both axes. OrthographicView OrthographicView is the preferred view for displaying 2D stimuli with traditional retino-centric coordinates. The properties to vary are the visual angles for the top and bottom boundaries (elevation) and left and right boundaries (azimuth). Stimuli drawn will have sizes and locations defined in terms of visual angles. In this example workflow, we have defined an orthographic view that extends 90 deg in visual angle for all 4 boundaries (essentially a hemisphere in front of the subject) and defined a circle to be drawn with a diameter of 90 degrees centered at 0 deg visual angle. This leads to a circle that takes up half the visual field. Although the outcome is the same with both the NormalizedView and OrthographicView examples note the differences in terms of units that the stimuli are drawn with. 3D Stimuli PerspectiveView PerspectiveView is the preferred view for displaying 3D stimuli such as 3D models or scenes (complex 3D models). The properties to vary are the eye/camera position, field of view, light position, target position, the up vector of the camera (this determines the roll/orientation) as well as the distance to the far and near clipping planes (the area that the camera can see). Stimuli drawn will have sizes and locations defined in terms of metric units. Warning Using a 2D DrawX stimuli node with a PerspectiveView will throw a method overload error. In this example workflow, we have replaced the 2D draw circle with a 3D DrawModel node to draw a 3D plane. CubemapView CubemapView is the preferred view for display 3D environments such as those commonly used for virtual reality or augmented reality. The properties to vary are the eye/camera position, light position, field of view, target position, as well as the distance to the far and near clipping planes (the area that the camera can see). Stimuli drawn will have sizes and locations defined in terms of metric units. In this example workflow, we use CubemapView to simulate the walls of a virtual 3D room. This example workflow is a stripped down version of the virtual reality corridor in Demos and requires downloading of the textures in that article. Note CubemapView requires two additional nodes for a basic workflow, a RenderCubemap operator from the Bonsai.Shaders package (included as a dependency) that renders the cubemap and a ViewWindow that looks out into the virtual environment. Note While the description of the operator suggests that you need to define six textures for each face of the cubemap, you can display an arbitary number of textures (including less than six). Other nodes to document (under construction) HMDview and RenderHMD"
  },
  "articles/faq.html": {
    "href": "articles/faq.html",
    "title": "Frequently Asked Questions | Bonvision",
    "keywords": "Frequently Asked Questions I can't see the window with the stimulus when I hit Start in Bonsai? In some cases, the window might appear outside of the screen. If that is the case, you can adjust the Location parameter in the CreateWindow operator by passing a pair of x,y values corresponding to the screen coordinates (for instance: 100,100). I see duplicate operators in Bonsai when adding operators, which one should I choose? As an example, the Timer operator that is used to control timing of stimuli exists in two versions, a Timer that belongs to the Bonsai.Reactive package and a Timer that belongs to the Bonsai.Shaders package. These two operators are not identical. The Bonsai.Reactive timer is controlled by the operating system while the Bonsai.Shaders version is tied to the refresh rate of the visual display. For BonVision, since we are using the Bonsai.Shaders package to present visual stimuli, using a Bonsai.Shaders version of the Timer or other timing operators ensures greater consistency and timing as it avoids clock drift and jitter when synchronizing multiple visual elements. However for other instances, you need to carefully consider the underlying behaviour of the different operators. For instance the Bonsai.Shaders version of the KeyDown operator only detects keys that are pressed when the shader window is in focus whereas the Bonsai.WindowsInput version of the KeyDown operator detects keys whenever they are pressed. In this instance which operator is preferable depends on your application. For instance, if you want to control visual stimuli with keypresses but not have it affect other workflows/windows that are running, the Bonsai.Shaders version of the KeyDown might be preferrable, but you need to ensure that the shader window is always in focus for when you want to control the visual stimuli. This is similar to how games confine keyboard input whenever they are running. On the other hand, if you have other workflow/windows running and may need to bring them up, choosing the Bonsai.WindowsInput version of the KeyDown operator will ensure that keypresses are always controlling the visual presentation, as long as you select keys that do not interfere with other. What is the difference between the different view operators, for instance, an OrthographicView, a ViewWindow, and a DrawViewport. Although the naming convention is a bit confusing, these operators all have different purposes. The drawing view operators (NormalizedView/OrthographicView/PerspectiveView) determine which region of the visual space is being drawn, as well as the units that are being used to draw stimuli sizes/location. The ViewWindow operator are basically windows through which the subject is looking at the visual environment. The DrawViewport operator are operators that define different displays for rendering viewing windows. For a more in depth explanation, check out this youtube video:"
  },
  "articles/gamma-calibration.html": {
    "href": "articles/gamma-calibration.html",
    "title": "Gamma | Bonvision",
    "keywords": "Gamma The gamma calibration workflows can be found here. What is gamma calibration? Consider a pixel on your monitor. When your program tells the computer what intensity that pixel should have -- e.g. 128 in an 8-bit grayscale color range -- that number will be translated by the video card into a pattern of voltage signals to the display, which will convert them to an appropriate light intensity, e.g. 10 photons/s. Intuitively, when your program doubles that numeric intensity, you would expect that the intensity of the pixel would also double. This would be a linear system – doubling the number in your program should double the amount of light emitted by the pixel. However, computer monitors and projectors don't quite work like this. For various reasons related to human visual perception and data compression, there are non-linearities between the numbers in your program and pixel intensity. For example, doubling the number in the program might triple the intensity of the pixel, and this might depend on the intensity you started with. When running visual neuroscience experiments we often would like to know the exact relationship between the numbers our computer program is specifying and the pixel intensity, and possibly compensate for these non-linearities when we present stimuli. This is the process of gamma calibration. We calibrate by creating a look-up table, consisting of 256 columns and 3 rows (one for each of the monitor primary colours – red, green and blue). When we send an image to the video-card, the last thing we do is pass the image through this look-up table. Additional info at: LearnOpenGL, Wikipedia, or here. Using BonVision for Gamma Calibration Hardware requirements: You will require a light sensor and a data acquisition device Light sensor: We have tested these scripts using two sensors – Open-source photodiode from Champalimaud Foundations’s Hardware Platform link Thorlabs amplified photodetector DISCONTINUED Data Acquisition device: We ran our tests on an Arduino board, and a HARP board. The main requirement is that you would need to be able to read it with Bonsai (it covers most DAQs). Testing display gamma This workflow can be used to test the linearity of the monitor with or without the gamma correction in BonVision. To test without the GammaCorrection, disable the GammaCorrection node in the workflow here. Setup: Connect the sensor to an analog channel of the DAQ and setup the AnalogInput node as appropriate for your DAQ by setting the Pin and PortName property. Place the sensor such that it is facing the monitor (or the light path if it is a projector). Make sure there are no additional light sources to the sensor. Test: Run the workflow! There are a few settings you might have to play with: Position and size of the display window. These can be setup in the option of the CreateWindow node. If the measurement is noisy you can change the parameters Count and Period in the options of the BrightnessRamp node. We set it at 255 steps (steps between 0-255) with a sampling time of 0.02 seconds per step. You might have to increase the sampling time depending on the temporal characteristics of the sensor and display. To reduce the total time taken to run the test, you can reduce the number of steps. E.g. For one of our 60Hz projector we used 20 steps sampled at 1s per step, to be confident of the measurements. You might have to reduce the spatial frequency of the DrawGrating node depending on the size of the display and sensor. Below is an example of the measurement made for a monitor. Note there is a curve (rather than line) on the left, and the sine wave has peaks sharper than the troughs. Making the monitor linear Option 1 (Preferred) – go with the hardware The hardware of most modern displays is typically linear (such as in LCD or LED displays). However, a gamma non-linearity is incorporated into the output to allow representing the full human perceptual range with just 8-bits for each color. Therefore displayed images will ‘look nice’ even with just 256 light levels. This gamma curve is incorporated at multiple levels, mainly in the settings of the physical display (every monitor is different) and in the OS (graphics card driver). In Windows 10, the OS settings can be calibrated using the Calibrate Display Colour app from the start menu. Move through the steps and max out the correction (it’ll make the monitor look brighter and greyer. Re-run the test with those settings to check if this made the display linear. If not, continue to option 2. Option 2 – use BonVision to Calibrate There are two workflows: GammaCalibration_Fit & GammaCalibration_FitGray. Follow steps similar to those above in Testing the Display to run these scripts. The look-up image is saved where specified in the FileName parameter of the SaveImage node. You can edit the CreateGammaLookup.cs in the Extensions folder within to have a different fitting if you prefer. Note: In case the BrightnessRamp node shows an error and is red, you might have to hit Reload Extensions in Bonsai, which is the rightmost icon on top."
  },
  "articles/installation.html": {
    "href": "articles/installation.html",
    "title": "Installation | Bonvision",
    "keywords": "Installation Install Bonsai from www.bonsai-rx.org. Once you open Bonsai, choose 'Manage Packages' and add additional packages: Starter Pack BonVision - you can find this by navigating to Package Source on the top right -> Community Packages BonVision has the same requirements as Bonsai: .NET framework on Windows 7 or later."
  },
  "articles/logging.html": {
    "href": "articles/logging.html",
    "title": "Logging | Bonvision",
    "keywords": "Logging By 'Logging' we refer to saving information relavant for the experiment. In general, there are four kinds of data one might want to log during an experiment: Duration of the experiment and timing of each frame When were the stimuli presented What are the stimulus parameters used in the experiment Keeping track of external events We created three nodes that can deal with all the three types of logging. These nodes are: FrameEventLogger, EventLog & LogEvent. The logger saves data to a .csv file and there are three aspects saved FrameEventLogger: This is used to setup a logger that can be used to It needs to be placed after RenderFrame. The first time this is encountered, it starts the clocks, both the frame counter and time. It also opens the .csv file that is specified where the information is saved. A logger then becomes a behaviour subject that can be accessed in the rest of the workflow. Note You can start the logger either at the start of the experiment which will keep logs globally, or within a trial which will save data with respect to the relevant trial. EventLogger: This is used to setup a logger that can be used to record stimulus/experiment parameters parameters but does not record frame event and timing. LogEvent: This is actually used to save the data to the file. A LogEvent node subscribes to a FrameEventLogger or EventLogger subject, and writes to the corresponding .csv file three different aspects Current frame index, Current Time, Logged information. The input to the LogEvent node can be the parameters that need to the saved (described below), and contain the format in which the data is saved. Warning When there are multiple FrameEventLogger or EventLogger subjects, we need to ensure that LogEvent subscribes to the right subject to write to the correct file. Warning There are options to overwrite, append, etc for the files, so make sure you do not lose information by overwriting the files. Here, we describe how to inplment the logging scenarios at the beginning of the article. A. Logging screen update / refresh times To log the frame index and the time at which every frame was presented, duplicate the RenderFrame node, connect a FrameEventLogger with a subject called Frames followed by a LogEvent node that subscribes to the Frames subject. Warning Although you can put the FrameEventLogger and LogEvent in the DrawCircle branch, in branches where there are conditional loops the FrameEventLogger might restart. Thus, its better to make a separate branch for logging events. B. Logging stimulus presentation To log stimulus presentation, create a second FrameEventLogger branch with a new subject called Stimulus, but this time, place a LogEvent node that subscribes to the Stimulus subject after a DrawX stimuli node. In this example workflow, the stimuli is presented after 5 seonds, and the LogEvent only logs when the stimuli is onscreen. Note This is a good example of starting multiple loggers to save different types of information in different files. C. Logging stimulus parameters To log stimulus parameters, we would use the same method for logging stimulus presentation, but connect the LogEvent to the parameter that is being varied. D. Logging external events To log external events that are happening (such as keypresses or an animal carrying out a nose poke), the process is similar to that of logging stimuli presentation/presentation. Create a new FrameEventLogger branch, but in this case with a new subject called Events, and place a LogEvent node that subscribes to the Events subject after the keypresses or event you want to record. Note The external events can be sampled at a different sampling frequency compared to the visual stimulus presentation. In the situation where the external data is at a higher rate, the frame index might not change as frequently, however, the time will remain precise Note The two LogEvents after the keypresses can subscribe to the same Events subject so you do not need to create a separate file for every event."
  },
  "articles/map-stimuli.html": {
    "href": "articles/map-stimuli.html",
    "title": "Map Stimuli | Bonvision",
    "keywords": "Map Stimuli Sphere Mapping When rendering 3D environments, in the case of 3D stimuli, BonVision applies by default a cubemap rendering approach and no additional transformation/operators are necessary. However, in the case of 2D stimuli, we use SphereMapping to render them onto the inside of a 3D sphere to display them in a 3D space. More info can be found in the Display Environments This workflow below draws a checkboard which is mapped to a sphere using SphereMapping. Note SphereMapping requires a ViewWindow. Note When drawing stimuli, SphereMapping requires a PublishSubject and SubscribeSubject pair (see the multiple stimuli for instructions on how to use Subjects and this link for an explanation of the reasons)."
  },
  "articles/mesh-mapping-calibration.html": {
    "href": "articles/mesh-mapping-calibration.html",
    "title": "Mesh Mapping | Bonvision",
    "keywords": "Mesh Mapping Protocol for producing a mesh-mapping file using Bonsai (EH, April 2021) Purpose Mesh mapping is performed to generate a mapping from pixel space (x,y) to visual angle space (azimuth, elevation), or equivalently cartesian coordinate space (x,y,z). Mesh mapping is generally required when the relationship between pixel space and visual angle/cartesian coordinate space is non-trivial, such as when projecting onto a demispherical dome. Hardware required The display surface for which you are producing a mesh map. Laser pointer (ideally one that clicks to stay on/off). System for accurately targeting laser pointer at a given azimuth and elevation (in degrees) from the perspective of the animal’s head position. We use a custom 3D printed part suitable for holding our laser pointer at intervals of 30 vertical degrees and a high-precision rotation mount for targeting specific azimuth angles. We use RSP1X15/M from ThorLabs. Overview We provide 3 Bonsai workflows and a Matlab script for producing a mesh mapping file for a curved display surface: MeshMapping_Generate is for interactively generating an initial mesh mapping .csv file in Bonsai. The Matlab script MeshMapping_MatlabInterp.m is for interpolating and formatting the Bonsai-generated mesh mapping .csv file for use with the BonVision MeshMapping node. MeshMapping_showCheckerboard draws a simple checkerboard to test the accuracy of your mesh mapping file. MeshMapping_correctPositions can be used to interactively adjust indiviudal points in your mesh mapping file. The final output is a .csv with 5 columns (no headers): (pos_X, pos_Y, norm_Az, norm_El, intensity). where pos_X and pos_Y are normalised screen positions of each cooordinate, norm_Az and normEl are normalized azimuth and elevation co-ordinates of each position and intensity is desired intensity values for each co-ordinate (generally a column of 1's). You can download the workflows from here. Protocol Step 1 - Generating initial mesh map Open the MeshMap_Generate workflow and enter the required parameters: Height and Width of display projector (in pixels). E.g. Width = 1280, Height = 800. The desired angular span of the display (HSpan for azimuth, VSpan for elevation). E.g. HSpan = 240, VSpan = 120. The number of subdivisions of the angular space which you wish to perform (HSubdiv for azimuth and VSubdiv for elevation). These values generate the grid of angular points you will manually assign. E.g. for HSpan = 240 and HSubdiv = 12 there will be 13 equally spaced points (0:20:240) specified along the azimuth for each elevation separate elevation. Specify the display device property of the CreateWindow node to the display you are mesh mapping (e.g. ‘Second’). The filename for the Mesh Mapping .csv file. You can now start the workflow. A blank shader window should fill the display surface being mesh mapped and a grid of circles representing the points to be assigned should be displayed on the display device which is showing the Bonsai GUI. The green circle indicates the current point being assigned. If you cannot see the grid, select the visualiser for the DrawGrid node. You may need to restart the workflow/assign the first point before the grid appears. Now work through the points to be assigned. For each point: Target the laser pointer at the angular position to be assigned. Using the mouse, position the small rendered circle on the display being mesh mapped to align with the laser. Mouse Keys may be useful for the final positioning. Once you are satisfied with the position of the circle, click the left mouse key. You can then save this point by pressing the ‘d’ keyboard key. The green circle on the grid of circles should now have moved to the next point to be assigned. Repeat the previous step. If you wish to reassign a point you can right-click the mouse to move back to a previous point. Once you have assigned all the required points close the shader window and workflow. The mesh mapping .csv file will be saved in the location you specified before starting the workflow. positioning the cursor where the laser is pointing Step 2 - Interpolating and formatting the mesh mapping file Open the matlab script MeshMapping_MatlabInterp or MeshMapping_3DMatlabInterp. Assign the variables: input .csv filename output .csv filename Angular Span (in degrees, as assigned in the MeshMapping_Generate workflow). Display Dim (in pixels, as assigned in the MeshMapping_Generate workflow). interpolation resolution for both azimuth and elevation. We suggest values that are factors of the angular span values. If producing a sphere-mapping meshmap for 2D stimuli you can now run the script (you may need to adjust the .csv writing function depending on your matlab version). You should now have an interpolated and correctly formatted mesh mapping .csv file to use in Bonsai. If producing a cube-mapping meshmap for 3D stimuli the script will produce a .bin file which you must process using the python interpolator.py script (note: to be consolidated). The output of the python script is a .bin file ready to use in your 3D bonsai workflow. Step 3 - Testing the mesh map Open the Bonsai workflow MeshMapping_drawCheckerboard. Point the filename property of the MeshMapping node to the output file from the Matlab script. Set the Bottom/Top and Left/Right properties of the OrthographicView node as the limits of the azimuth and elevation co-ordinates being presented (related to HSpan and VSpan from Step 1). E.g. Bottom = -30, Top = 90, Left = -120, Right = 120. Set the ExtentX and ExtentY of the DrawCheckerboard node as the HSpan and VSpan values from Step 1. Specify the desired number of rows and columns (VSubdiv and HSubdiv, for example). Run the workflow and ensure the checkerboard is displayed correctly. Each square should cover an equal amount of angular space as viewed from the perspective of the animals head position. Corners of each square should lie along meridians and parallels of each other. Note if the checkerboard renders with jagged edges then adjusting the interpolation values in Step 2 may provide a solution. testing the meshmap with a checkerboard - note the warping in the bottom right Step 4 - Refine mesh map (optional) If step 3 demonstrated imperfections in the mesh map then you can choose to adjust individual points. Open the Bonsai workflow MeshMapping_correctPositions. Set the resolution values (Height and Width) of the shader window as per your initial settings used for mesh mapping generation. Ensure the shader window is pointing to the correct display device (e.g. ‘Second’). Specify the desired output filename of the corrected mesh mapping .csv file. For each point you wish to adjust perform the following: Using the mouse move the cursor to the point you wish to adjust. Press the keyboard ‘g’ key to ‘get’ the point. Text will appear to notify you of the point you are adjusting (in angular coordinates). Move the mouse cursor to the new desired location (i.e. to an updated position specified by your laser pointer). Press ‘s’ to set the point. You can press 's' multiple times until you are satisified with the new placement. Once you have finished making adjustments, press the ‘k’ key to save the new mesh map file. The new file will have the same format as the output of the MeshMapping_Generate workflow. You should now perform steps 2 and 3 again to interpolate and test your mesh map. Repeat this process iteratively as required. correction worflow"
  },
  "articles/stimuli-alternative.html": {
    "href": "articles/stimuli-alternative.html",
    "title": "Alternative Stimuli Creation | Bonvision",
    "keywords": "Alternative Stimuli Creation Dynamic Textures In addition to loading premade textures and videos, BonVision can display dynamic textures generated online or from other sources. In this example workflow, we use dynamic textures to display a webcam feed. Double click the TextureResources node and create a Texture2D resource and name it DynamicVideo. Add a basic Bonvision draw image workflow with a DrawImage node drawing the texture DynamicVideo. Add a CameraCapture node and feed the output to a UpdateTexture node. Loading from CSV Alternatively, one can also load stimuli parameters from a CSV file. In this example workflow, we load grating stimuli parameters from a CSV file to draw a series of grating stimuli. Load a CSV file with 4 columns for Orientation, TemporalFrequency, Contrast and Duration using the CsvReader node. Use an ExpressionTransform node with the script below to parse our integers as variables: new(Double.Parse(it[0]) * Math.PI/180 as Orientation, Double.Parse(it[1]) as TemporalFrequency, Double.Parse(it[2]) as Contrast, Double.Parse(it[3]) as Duration ) Use an InputMapping node to match the variables from the output of the ExpressionTransform node to the properties of the CreateGratingTrial node (In the example workflow, because we have matched the variables the InputMapping node takes on the name of the variables being mapped). Shawn's note Does this only apply to grating stimuli? or can this be used for other stimuli too? Loading from scripting to be added"
  },
  "articles/stimuli-animating.html": {
    "href": "articles/stimuli-animating.html",
    "title": "Animating Stimuli | Bonvision",
    "keywords": "Animating Stimuli Basic animation in BonVision involves manipulating one or more properties in a DrawX node. For instance, to make a circle move across the screen, you would vary the LocationX parameter in a DrawCircle node. To get started: Right click on any DrawX node and externalize the property you want to manipulate. BonVision provides a RangeAnimation operator to generate a linear range of values for a specified duration of time. Connect a RangeAnimation operator to the parameter you externalized and change the RangeBegin, RangeEnd and Duration. Add a Repeat operator if you want the animation to repeat between the RangeAnimation and DrawX node. The workflow will look something like this (which shows a circle moving across the screen repeatedly) Note The RangeBegin and RangeEnd parameter depends on the drawing region. For a NormalizedView -1 to 1 represents the edges of the screen. Note To vary more than 1 parameter at a time if they share the same RangeAnimation parameters, you can externalize more than 1 property at a time and they will be grouped together. To prevent parameters from being grouped together, connect a RangeAnimation operator to the first externalized property before externalizing a second property. For an additional example of this, see the Looming/Sweeping demo in the Demo page."
  },
  "articles/stimuli-multiple.html": {
    "href": "articles/stimuli-multiple.html",
    "title": "Multiple Stimuli | Bonvision",
    "keywords": "Multiple Stimuli BonVision has three methods for drawing multiple stimuli in the same window. Array Primitives For several stimuli primitives, BonVision includes array versions of these primitives that can be used to draw several of them simultaneously. These primitives can only be used to draw duplicate stimuli but with different positions. Shawn's note - I would like to add more details here about generating the input for these primitives but I am unable to find an example workflow to copy from and have not been able to figure it out myself. I saw an example on https://bonsai-rx.org/docs/tutorials/scripting.html but have trouble getting the CSharpTransform operator to work. Using SelectMany to Pass An Array of Values For finer control over the stimulus parameters, one can pass multiple values for each of the properties in a DrawX stimuli using a SelectMany operator. In this example workflow, We have generated two ranges of values using a ParameterRange operator, which we then Zip and pass along to a SelectMany operator named Create Gratings. The SelectMany operator generates one observable sequence for each input then merges the results into a single sequence. Double click on the SelectMany operator to view the embedded workflow. Within the SelectMany operator, we use an InputMapping operator to map the two values to the LocationX and Contrast of a DrawGrating node. Lastly we use a CombineLatest operator to issue a Draw call for each element that is produced. The end result is a row of gratings with different contrast and position. Shawn's note - This is how I understand this example workflow I saw on the Bonvision Examples repo, not sure if the explaination is correct. Note The DrawStimuli nodes in the example workflow are a PublishSubject and SubscribeSubject pair which we will cover below. Publish and Subscribe Subject For different stimuli, we can use the PublishSubject and SubscribeSubject operators to give multiple drawing commands to the RenderFrame operator. Subjects are a special type of operator that allow reusing and sharing of observable sequences. To get started: Connect a PublishSubject operator to the viewport (in our example workflow below, a NormalizedView) and give it a name, like DrawStimuli. Add multiple SubscribeSubject operators for each of the stimuli type you want to draw. In the SubscribeSubject operators, you will need to select the name you have given to the Subject you have created (in this example, DrawStimuli) Connect DrawX operators to each SubscribeSubject operator The end result should look something like this example workflow, which draws a circle and quad side by side. For a video walkthrough of this process, see this youtube video. Presenting multiple stimuli sequentially To present multiple stimuli sequentially, we can use the same PublishSubject and SubscribeSubject operators but add timers to them. Timing will be covered in the Timing Stimuli article,"
  },
  "articles/stimuli-neuroscience.html": {
    "href": "articles/stimuli-neuroscience.html",
    "title": "Neuroscience Stimuli | Bonvision",
    "keywords": "Neuroscience Stimuli Sparse Noise The SparseNoise operator generates a non-overlapping discrete sparse grid of randomly activated quads. Drawing the stimuli produced from the SparseNoise operator is a little different from the other DrawX stimuli. Add a Texture2D resource called DynamicVideo using the TextureResource operator. Add a DrawImage operator that renders the DynamicVideo texture. Connect a UpdateTexture operator to the SparseNoise operator and choose the DynamicVideo texture to update. Add logging information? Gratings As grating stimuli are commonly used in visual physiology experiments, we have created a few specialized nodes that make it convenient to design grating experiments very easily. Shawn's note - currently some of these nodes appear to be broken, awaiting feedback on https://github.com/bonsai-rx/bonsai/issues/1832 Nodes to document GratingsSpecification, CreateGratingTrial, GratingSequence, DrawGrating"
  },
  "articles/stimuli-timing.html": {
    "href": "articles/stimuli-timing.html",
    "title": "Timing Stimuli | Bonvision",
    "keywords": "Timing Stimuli Bonsai provides several operators that can be used in conjunction with BonVision operators to control the timing of stimuli presentation. Triggering Stimuli To control the onset of stimuli, use the SubscribeWhen operator, which initiates the draw sequence when it detects a notification from a linked operator. Starting from a basic DrawCircle workflow, add a SubscribeWhen operator after the DrawCircle operator. Connect a Timer operator to the SubscribeWhen operator and adjust the DueTime property to control when the stimuli comes on. This workflow draws a circle after five seconds has elapsed. Warning When choosing a Timer operator, you might see different versions of it in Bonsai. Choose the Bonsai.Shaders version. See the FAQ for an indepth discussion of when to choose between duplicate operators. Terminating Stimuli To control the duration of stimuli, use a TakeUntil operator, which terminates the draw sequence when it detects a notification from a linked operator. Simply replace the SubscribeWhen operator with the TakeUntil operator. This workflow starts with a drawn circle, and the circle dissappears after five seconds. Combining Triggering and Terminating Combine the operators together to control both the onset and offset of stimuli. Warning The order of operators is important and the sequence goes from right to left. Reversing the operators will cause the sequence to not produce any output. This workflow draws a circle after two seconds has elapsed, and the circle remains on screen for two seconds. Looping Stimuli To loop stimuli, add a Repeat operator to the end of the sequence. This workflow loops a circle for two seconds on and two seconds off. Note If you want the stimuli to repeat a set number of times instead of infinitely, use a RepeatCount operator instead. Controlling Timing of Multiple Stimuli To control the presentation of multiple stimuli, use a PublishSubject operator in conjunction with a SubscribeSubject operator to draw multiple stimuli as outlined in the Multiple Stimuli article. For each DrawStimuli branch, add separate SubscribeWhen, TakeUntil and Repeat operators. Since the branches are separate, they can have different timing progressions. This workflow below draws a circle on the left and a quad on the right with different timings for both. Sequential Presentation of Multiple Stimuli For sequential presentation of multiple stimuli that are not present at the same time, one can use the Concat operator to join the multiple branches of DrawStimuli. The Concat operator combines any number of observable sequences as long as each sequence terminates successfully. Note The Repeat operator is moved out of each branch and added to the Concat operator. Leaving it in a branch causes that branch to loop and not terminate successfully, which prevents the execution of the Concat step. The workflow below alternates between a circle on the left and a quad on the right. Controlling Stimuli Presentation with Events instead of Time Finally, both the SubscribeWhen and TakeUntil operators can be linked to other operators to control stimuli onset and offset using events rather than time. For instance, by replacing the Timer operator with a KeyDown operator, stimuli presentation can be linked to keypresses. This workflow draws a circle when the space bar is pressed, and the circle disappears when the a button is pressed. This also opens up possibilities for close-loop presentation of visual stimuli. For instance, visual stimuli can be linked to lever presses for operant conditioning tasks, as well as to subject movement (for instance when an animal crosses into an arena). Shawn's note might be worth a separate expanded \"close-loop\" article. Video Walkthrough For a video walkthrough of many of the steps covered in this article, check out this youtube video."
  },
  "articles/syncing.html": {
    "href": "articles/syncing.html",
    "title": "Syncing | Bonvision",
    "keywords": "Syncing In this article, we will cover how to sync BonVision experiments with other systems (e.g. neural recordings) with a photodiode, which has been used historically in vision neuroscience. While there are alternative methods of syncing (such as through TTL pulses which can be sent through Bonsai), syncing using a photodiode is a bit more precise and closer to ground truth because we know precisely when the stimulus is presented on the screen rather than when the computer has sent out a signal to update the display (which might have some delay). To sync with a photodiode, we have a small square in the corner of the screen (that is not visible to the subject) which we flip between black and white, which we can then observe with a photodiode. To set this up: Use a DrawQuad to draw a square and position the square in the corner of the screen. Externalize the ColorR, ColorG and ColorB properties of the DrawQuad operator to control the color of the square. Create a BehaviourSubject operator and name it QuadState, set a default Float value of 0 (for black), and link a SubscribeSubject operator subscribing to QuadState to the externalized ColorR, ColorG and ColorB properties. Within our pipeline for drawing a visual stimulus, we can add a Sink operator that updates QuadState whenever the stimulus is presented or when the stimulus is turned off. Sink operators do not modify the input or output items in any way but can trigger an external action. This example workflow shows a directional tuning stimulus together with a flashing square for syncing with a photodiode. You will need to expand the CreateObservable -> DirStim grouped workflows to see the Sink operators (named UpdatePD) which are embedded in the visual stimulus drawing pipeline. For a video walkthrough of this process, check out this youtube video."
  },
  "index.html": {
    "href": "index.html",
    "title": "| Bonvision",
    "keywords": "BonVision An open-source software package to create and control visual environments. Paper Twitter Youtube BonVision is developed by the Saleem Lab & Solomon Lab at the UCL Institute of Behavioural Neuroscience in collaboration with NeuroGEARS. BonVision’s key features include: Naturally closed-loop system based on reactive coding of the Bonsai framework Handles 2D and 3D stimuli with equal ease Visual environment generated independent of display configuration Graphical programming language of the Bonsai framework Can be used for Augmented Reality, Virtual Reality or 2D visual stimuli Does not require the observer to be in a fixed position Video Walkthrough More Bonvision videos on specific topics can be found on our youtube channel. Publication / Citation G Lopes, K Farrell, E A B Horrocks, C Lee, M M Morimoto, T Muzzu, A Papanilolaou, F R Rodrigues, T Wheatcroft, S Zucca, S G Solomon, A B Saleem, (2021) Creating and controlling visual environments using BonVision. eLife link"
  }
}